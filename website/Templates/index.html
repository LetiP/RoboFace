<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>RoboFace</title>

<link rel="stylesheet" type="text/css" href="../Static/Content/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" href="../Static/Content/RoboFace.css" />
<script src="../Static/Scripts/jquery-3.2.0.slim.min.js"></script>
<script src="../Static/Scripts/bootstrap.min.js"></script>

</head>
<body>
	<nav class="nav navbar-default navbar-fixed-top">
		<div class="container">
			<div class="navbar-header">
				<button class="navbar-toggle collapsed" aria-expanded="false" aria-controls="navbar" type="button" data-toggle="collapse" data-target="#navbar">
					<span class="sr-only">Toggle navigation</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
				<a class="navbar-brand" href="#"> RoboFace </a>
				<a class="face" href="#"><img src="../Static/Content/Zeichenfläche 1@0.5x.png" style="max-width: 23%; box-shadow: 0px 0px 0px;"></a>
			</div>
			<div class="navbar-collapse collapse" id="navbar">
				<ul class="nav navbar-nav">
					<li class="active"><a href="#">Home</a></li>
					<li><a href="docu.html">Documentation</a></li>
					<li><a href="theo.html">Theory</a></li>
				</ul>
			</div>
		</div>
	</nav>
	<div class="container" style="margin-top: 50px">
		<h1>RoboFace</h1>
		<div class="row">
			<div class="col-md-3">
				<img src="../Static/Content/roboFace.jpg" style="max-width:58%;">
			</div>
			<div class="col-md-3">
				<h4>Kevin Kiefer</h4>
				<p>5th semester informatics</p>
				<h4>Letiția Pârcălăbescu</h4>
				<p>3rd semester informatics</p>
				<br />
				<br />
				<br />
				<br />
				<h4>Supervisors</h4>
				<p>Gero Plettenberg and Benjamin Reh</p>
			</div>
			<div class="col-md-6">
				<img src="../Static/Content/faceEdited.jpg" style="max-width: 100%;">
			</div>
		</div>
		<h2>Task</h2>
		<p>
			The existing robotic face reacts on visual stimuli by producing acoustic and mimic signals.
			In order to achieve this, we implemented face and attribute recognition recognition.
			Furthermore, a voice output should indicate a reaction on the analysed face that RoboFace
			contemplates. This face is also tracked by the robot in order to maintain eye contact.
		</p>
		<h2>Milestones</h2>
		<ol>
			<li>overwriting the existing codebase</li>
			<li>face recognition</li>
			<li>face attribute detection</li>
			<li>voice/sound output</li>
			<li>face tracking</li>
		</ol>
		<h2>Source code</h2>
		<a href="https://github.com/LetiP/RoboFace">https://github.com/LetiP/RoboFace</a>
	</div>

	<nav class="navbar navbar-default">
	    <div class="container text-right">
	        <p class="navbar-text col-md-12 col-sm-12 col-xs-12">&copy; Letiția Pârcălăbescu, Kevin Kiefer</p>
	    </div>
	</nav>

</body>
</html>
