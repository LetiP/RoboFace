<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>RoboFace</title>

<link rel="stylesheet" type="text/css" href="../Static/Content/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" href="../Static/Content/RoboFace.css" />
<script src="../Static/Scripts/jquery-3.2.0.slim.min.js"></script>
<script src="../Static/Scripts/bootstrap.min.js"></script>

</head>
<body>
	<nav class="nav navbar-default navbar-fixed-top">
		<div class="container">
			<div class="navbar-header">
				<button class="navbar-toggle collapsed" aria-expanded="false" aria-controls="navbar" type="button" data-toggle="collapse" data-target="#navbar">
					<span class="sr-only">Toggle navigation</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
				<a class="navbar-brand" href="index.html">RoboFace</a>
				<a class="face" href="index.html"><img src="../Static/Content/Zeichenfläche 1@0.5x.png" style="max-width: 23%; box-shadow: 0px 0px 0px;"></a>
			</div>
			<div class="navbar-collapse collapse" id="navbar">
				<ul class="nav navbar-nav">
					<li><a href="index.html">Home</a></li>
					<li class="active"><a href="#">Documentation</a></li>
					<li><a href="theo.html">Theory</a></li>
				</ul>
			</div>
		</div>
	</nav>
	<div class="container" style="margin-top: 50px">
		<h1>Documentation</h1>
		<h2>Setup guide for the robot</h2>
		<h3>Hardware setup</h3>
		<p>
			There are 2 servos used to move the head and 10 more to display facial expressions. The mini maestro 18-channel usb servo controller is used to control them.
		</p>

		<div class="row">
			<div class="col-md-6">
				<img src="../Static/Content/RoboFaceNeutral.svg" style="max-width:50%; display: block; margin: auto"">
			</div>
			<div class="col-md-6">
				<img src="../Static/Content/RoboFaceBack.svg" style="max-width: 50%; display: block; margin: auto"">
			</div>
		</div>

		<h3>Software setup</h3>
		<p>

			A python interface is build on top of the C++ code controlling the robots hardware. Which may be used like this:
			<pre><code>
	&gt;&gt;&gt; import face
	&gt;&gt;&gt; f = face.Face()
	&gt;&gt;&gt; f.happy()               # look happy (possibly moves the head)
	&gt;&gt;&gt; f.angry(moveHead=False) # look angry but don't move the head
	&gt;&gt;&gt; f.moveHead(x, y)        # move the head and possibly the eyes to the position (x, y),
                                    # where (x, y) are coordinates within the current webcam frame
			</code></pre>
		<p>
			Further facial expressions and head movement functions as well as optional configuration parameters
			for the constructor are provided. Please call <code>help(Face)</code> from within your python interpreter for more information.
		</p>
		<p>
			In case you need a more specific control over each servo you must use the C++ api, which is a superset of the python api. The major addition here, which is visible to the user, is the notion of a "ServoConfig" and the corresponding <code>applyConfig()</code> function.<br>
			For example:
			<pre><code>
	#include <face.h>
	int main()
	{
		Face f = Face();
		ServoConfig<3> config = {{1, 5, 10}, {4500, 8000, 6000}};
		// set servo 1, 5, and 10 to the positions 4500, 8000 and 6000
		f.applyConfig(config);
	}
			</code></pre>
		</p>
		<p>
			The code depends on the pololu-usb-sdk and RapaPololuMaestro library. These are available on github:
			<ul>
			<li><a href="https://github.com/pololu/pololu-usb-sdk">https://github.com/pololu/pololu-usb-sdk</a>
			<li><a href="https://github.com/jbitoniau/RapaPololuMaestr://github.com/jbitoniau/RapaPololuMaestro">https://github.com/jbitoniau/RapaPololuMaestr://github.com/jbitoniau/RapaPololuMaestro</a>
			</ul>
		</p>
		<p>
			For using the face attribute detection software, a standard python (2.7 or 3.5) anaconda
			installation should additionally include <code>opencv, keras</code>. Additionally, for text to speech synthesis, you should install <code>gTTS, pygame</code>. You can easily install them using
			conda with the following commands:
			<pre><code>
	conda install -c menpo opencv3=3.1.0
	conda install keras
	pip install gTTS
	pip install pygame
			</code></pre>
		<p></p>
		<p>
			Then for running the software, execute the python script <code>face_detection/face_detection.py</code>
		</p>
		<p>
			If you eventually want to retrain the network for further improvement of the results,
			then you should take a look in te <code>neural_network_training/train_normalised.py</code>
			script.
		</p>
	</div>

	<nav class="navbar navbar-default">
		<div class="container text-right">
			<p class="navbar-text col-md-12 col-sm-12 col-xs-12" style="font-size:80%;">&copy; Letiția Pârcălăbescu, Kevin Kiefer</p>
		</div>
	</nav>

</body>
</html>
